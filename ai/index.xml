<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ais on 流年</title>
        <link>http://localhost:1313/ai/</link>
        <description>Recent content in Ais on 流年</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>流年</copyright>
        <lastBuildDate>Wed, 19 Feb 2025 08:38:25 +0000</lastBuildDate><atom:link href="http://localhost:1313/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大模型训练推理资源与计算量评估</title>
        <link>http://localhost:1313/ai/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E8%B5%84%E6%BA%90%E4%B8%8E%E8%AE%A1%E7%AE%97%E9%87%8F%E8%AF%84%E4%BC%B0/</link>
        <pubDate>Wed, 19 Feb 2025 08:38:25 +0000</pubDate>
        
        <guid>http://localhost:1313/ai/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E8%B5%84%E6%BA%90%E4%B8%8E%E8%AE%A1%E7%AE%97%E9%87%8F%E8%AF%84%E4%BC%B0/</guid>
        <description>&lt;h2 id=&#34;计算量评估&#34;&gt;计算量评估
&lt;/h2&gt;&lt;h4 id=&#34;前馈神经网络计算量&#34;&gt;前馈神经网络计算量
&lt;/h4&gt;&lt;p&gt;前馈神经网络：Y = XW +B&lt;/p&gt;
&lt;img width=&#34;200&#34; height=&#34;auto&#34; src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/d1bf250b40fa27686da6046c2e7ef5df7570826e956971577473587fe83bdb02.png&#34; &gt;
&lt;p&gt;在这个过程中，完成的运算如下：&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
x_0 &amp;amp; x_1 &amp;amp; x_2
\end{bmatrix}
\times
\begin{bmatrix}
w_{00} &amp;amp; w_{01} \
w_{10} &amp;amp; w_{11} \
w_{20} &amp;amp; w_{21}
\end{bmatrix} +
\begin{bmatrix}
b_0 \
b_1
\end{bmatrix}
$$
其中，W是权重矩阵，X是输入向量，B是偏置项。即：
$$
y = \begin{bmatrix}
y_0 \
y_1
\end{bmatrix}
\begin{matrix}
y_0 = w_{00}x_0 + w_{01}x_1 + b_0\
y_1 = w_{10}x_0 + w_{11}x_1 + b_1\&lt;br&gt;
\end{matrix}&lt;/p&gt;
&lt;p&gt;$$&lt;/p&gt;
&lt;p&gt;上述2个公式中，每个公式都有3个加法、3个乘法计算。所以[1,3]的矩阵和[3,2]的矩阵相乘共包含 2&lt;em&gt;1&lt;/em&gt;3&lt;em&gt;2 =12 次浮点计算量(称为FLOPs)。从而推广到一般：[m,k]的矩阵和[k,n]的矩阵相乘，需要2&lt;/em&gt;m&lt;em&gt;k&lt;/em&gt;n FLOPs。而GPU在不同精度单位下，浮点数运算的效率是不同的。例如，A100在16位精度(FP16或BF16)下每秒可以进行$314&lt;em&gt;10^{12}$次浮点运算。而在32位精度下，每秒只能进行$156&lt;/em&gt;10^{12}$次浮点运算。所以，我们可以理所当然的想到一个提速思路 - 让所有运算在低精度下进行来提高训练/推理效率。但是，这里有个无法忽略的问题：某些计算必须要在高精度下进行。例如全程在低精度下进行模型训练，往往会出现由于精度不够导致数值溢出和无法收敛的问题。所以目前大模型训练通常采用的是混合精度方式进行：前向传播、反向传播这些无需高精度的计算采用16位精度(FP16或BF16)进行，优化器状态更新在32位精度(FP32)进行。而模型推理的要求就比较低，可以在16位、8位甚至4位精度进行，整个任务的计算效率非常高。&lt;/p&gt;
&lt;h3 id=&#34;模型计算量分析&#34;&gt;模型计算量分析
&lt;/h3&gt;&lt;p&gt;$$
训练计算量 = F_{前向传播} + F_{反向传播}\
推理计算量 = F_{前向传播} \
F_{反向传播} = 2*F_{前向传播}
$$&lt;/p&gt;
&lt;p&gt;接下来进行$F_{前向传播}$的计算推导：&lt;/p&gt;
&lt;p&gt;先确定符号：我们令B对应batch size，s对应sequence length，h对应hidden dimension，l对应layers number；接着，我们再来观察大模型结构：大模型本身由l个transformer块串联而成。此外，首transformer块前和尾transformer块后还有一些结构。所以大模型的算力估算可以分为两大块：一、l个transformer块中的FLOPs；二、其他结构中的FLOPs：&lt;/p&gt;
&lt;h3 id=&#34;transformer块中每个transformer块都由多头注意力结构和mlp两种结构构成&#34;&gt;transformer块中，每个transformer块都由多头注意力结构和MLP两种结构构成：
&lt;/h3&gt;&lt;img width=&#34;200&#34; height=&#34;auto&#34; src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/e4470333445feb151d73a37d79377254174c96c1240b57b1a0c883e24b551025.png&#34;&gt;
&lt;h4 id=&#34;多头注意力机制所需计算量&#34;&gt;多头注意力机制所需计算量：
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/250da86b2e1b6fb734121a17b5125e55f7d9f8eac87875c3ac6ba3654b8827da.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;250da86b2e1b6fb734121a17b5125e55f7d9f8eac87875c3ac6ba3654b8827da&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;QKV计算量：&lt;/strong&gt;
$$
Q = XW^Q, K=XW^K, V=XW^V, 其中：
x \in [B,s,h], W^Q\in[h,h/a]
$$
涉及计算量大致如下：
$$3&lt;em&gt;2&lt;/em&gt;B&lt;em&gt;s&lt;/em&gt;h&lt;em&gt;h/a&lt;/em&gt;a=6Bsh^2,其中a是多头注意力机制的head数。
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意力计算量&lt;/strong&gt;：&lt;br&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;注意力分数计算
单头注意力分数一般采用如下计算：
$$
attention = QK^T / \sqrt(d_k)
$$
计算量为：
$$
2B&lt;em&gt;s&lt;/em&gt;h/a&lt;em&gt;s=2Bs^2h/a,其中Q \in [B,s,h/a], K^T \in[B,h/a,s]
$$
因此多头注意力分数整体计算量：
$$
2Bs^2h/a&lt;/em&gt;a=2Bsh^2
$$&lt;/li&gt;
&lt;li&gt;注意力输出层计算量：
单头注意力输出层计算量：
计算公式为：
$$
Z= attention \times V, 其中attention \in [B,s,s], V\in[B,s,h/a]
$$
计算量为：
$$
2B&lt;em&gt;s&lt;/em&gt;s&lt;em&gt;h/a=2Bs^2h/a
$$
因此多头注意力输出层计算量为：$2Bs^2h/a&lt;/em&gt;a=2Bs^2h$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;多头注意力合并层计算量&lt;/strong&gt;&lt;br&gt;
计算公式为：
$$
y = W^OZ + B \
其中,Z\in[B,s,h], W^O \in [h, h], Z为多头注意力输出层结果拼接
$$
计算量为：
$$
2B&lt;em&gt;s&lt;/em&gt;h*h=2Bsh^2
$$
因此整个自注意力层的计算量为：
$$
4Bs^2h+8Bsh^2
$$&lt;/p&gt;
&lt;h3 id=&#34;mlp层所需计算量&#34;&gt;MLP层所需计算量
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;激活值和第一个线性层相乘：$[B,s,h]*[h,4h] 共8Bsh^2$ FLOPs；&lt;/li&gt;
&lt;li&gt;激活值和第二个线性层相乘：$[B,s,4h]*[4h,h] 共8Bsh^2$ FLOPs；&lt;/li&gt;
&lt;li&gt;激活层为约0FLOPs：GeLU是确定的数学缩放公式，可认为无需矩阵乘；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单个MLP共有包含$16Bsh^2$$ FLOPs。&lt;br&gt;
因此，l个transformer块的FLOPs为：$24Bsh^2+4Bs^2h$，所有transformer块的FLOPs为：$l(24Bsh^2+4Bs^2h)$。&lt;/p&gt;
&lt;h3 id=&#34;其他结构所需计算量&#34;&gt;其他结构所需计算量
&lt;/h3&gt;&lt;p&gt;主要是最终输出层，计算公式为：
$$
y = XW^O + B, 其中X\in[B,s,h], W^O \in [h,V], V为字典大小
$$
其计算量大小为：
$$
2B&lt;em&gt;s&lt;/em&gt;h&lt;em&gt;V=2BsVh
$$
综上，整个模型的前向传播计算量为：
$$
F_{前向传播} = l(24Bsh^2+4Bs^2h)+2BsVh \
= 24Bsh^2l+4Bs^2hl+2BsVh \
= 24Bsh^2l(1+\frac{s}{6h}+\frac{V}{12lh})
$$
而通常在大模型中，6h远大于s，12lh远大于V，所以还可以进一步简化：
$$
F_{前向传播} = 24Bsh^2l
$$
因此可推断，训练与推理所需的计算量为：
$$
F_{训练} = 3F_{前向传播} = 72Bsh^2l \
F_{训练} = 4F_{前向传播} = 96Bsh^2l,全量参数计算时 \
F_{推理} = F_{前向传播} = 24Bsh^2l
$$
粗略估算一般基于transformer的大模型的参数量为$12lh^2$,可以发现：
1）模型训练中：如果没有应用激活值重计算，单模型副本处理每个tokens时，单参数上算力需求约为6FLOPs($\frac{72Bsh^2l}{12lh^2&lt;/em&gt;B*s}$)。如果应用全激活值重计算，提升至8FLOPs；
2）模型推理中：单模型副本处理每个tokens时，单参数上算力需求约为6FLOPs；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/b7530fd66541fc9ea2132a8dd205a7011dda6210ab3ac10ac39d42ed4cc6c04c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;b7530fd66541fc9ea2132a8dd205a7011dda6210ab3ac10ac39d42ed4cc6c04c&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;最常用来测量每秒浮点运算次数的基准程序（benchmark）之一，就是Linpack。
一个MFLOPS（megaFLOPS）等于每秒一百万（=10^6）次的浮点运算，
一个GFLOPS（gigaFLOPS）等于每秒十亿（=10^9）次的浮点运算，
一个TFLOPS（teraFLOPS）等于每秒一万亿（=10^12）次的浮点运算，
一个PFLOPS（petaFLOPS）等于每秒一千万亿（=10^15）次的浮点运算，
一个EFLOPS（exaFLOPS）等于每秒一百亿亿（=10^18）次的浮点运算。&lt;/p&gt;
&lt;h3 id=&#34;模型训练时间估算&#34;&gt;模型训练时间估算
&lt;/h3&gt;&lt;p&gt;根据阿姆达尔定律，由于整个系统中有网络通信等无法并行加速项的存在，集群中存在加速比上限。通常，训练集群中的GPU利用率通常约30%～55%之间。集群训练耗时计算公式如下：
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/c3b91e8f5a779118ff3f119f3152c5aec3f0bc54e4712e757a9e828bdd53d74b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;c3b91e8f5a779118ff3f119f3152c5aec3f0bc54e4712e757a9e828bdd53d74b&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_43925843/article/details/145626893&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_43925843/article/details/145626893&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.nvidia.cn/data-center/v100/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.nvidia.cn/data-center/v100/&lt;/a&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/f048f9cb18ca409edeeb27e838ce9a011cf21bd80c82afa9ff3ca00fa33136ee.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;f048f9cb18ca409edeeb27e838ce9a011cf21bd80c82afa9ff3ca00fa33136ee&#34;
	
	
&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E8%BD%AF%E7%A1%AC%E4%BB%B6%E4%BE%9D%E8%B5%96&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E8%BD%AF%E7%A1%AC%E4%BB%B6%E4%BE%9D%E8%B5%96&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;LLaMA Factory 微调所需的硬件资源计算主要基于&lt;strong&gt;模型参数量&lt;/strong&gt;、&lt;strong&gt;微调方法&lt;/strong&gt;和&lt;strong&gt;训练配置&lt;/strong&gt;三个核心维度。以下是具体计算方法与典型场景示例：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;一显存需求计算公式&#34;&gt;&lt;strong&gt;一、显存需求计算公式&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;显存占用（GB）主要包含以下部分：
$$
\text{显存} = \text{模型参数显存} + \text{梯度显存} + \text{优化器状态显存} + \text{激活值显存}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 模型参数显存&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全参数微调（FP16）&lt;/strong&gt;：参数量 × 2 bytes&lt;br&gt;
（例如 7B 模型：7×10⁹ × 2 / 10⁹ = 14GB）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LoRA（FP16）&lt;/strong&gt;：仅需存储低秩矩阵（约 0.1%-1% 参数量）&lt;br&gt;
（例如 7B 模型：14GB × 1% ≈ 0.14GB）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;QLoRA（4-bit）&lt;/strong&gt;：参数量 × 0.5 bytes&lt;br&gt;
（例如 7B 模型：7×10⁹ × 0.5 / 10⁹ = 3.5GB）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. 梯度与优化器状态&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全参数微调（Adam优化器）&lt;/strong&gt;：参数量 × 4 bytes（梯度+优化器状态）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LoRA/QLoRA&lt;/strong&gt;：仅需存储少量梯度（可忽略）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. 激活值显存&lt;/strong&gt;&lt;br&gt;
与批次大小（batch size）和序列长度（seq_len）相关，计算公式：&lt;br&gt;
$$
\text{激活值显存} \approx \text{batch_size} \times \text{seq_len} \times \text{hidden_dim} \times 2 \text{ bytes}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;二典型场景硬件需求&#34;&gt;&lt;strong&gt;二、典型场景硬件需求&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模型规模&lt;/th&gt;
&lt;th&gt;微调方法&lt;/th&gt;
&lt;th&gt;显存需求（估算）&lt;/th&gt;
&lt;th&gt;推荐 GPU 配置&lt;/th&gt;
&lt;th&gt;数据来源&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;7B&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;全参数（FP16）&lt;/td&gt;
&lt;td&gt;60GB&lt;/td&gt;
&lt;td&gt;2×A100 80GB&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;7B&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;QLoRA（4-bit）&lt;/td&gt;
&lt;td&gt;6GB&lt;/td&gt;
&lt;td&gt;单卡 RTX 3090/4090&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;13B&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;LoRA（FP16）&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;单卡 A100 40GB&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;70B&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;全参数（FP16）&lt;/td&gt;
&lt;td&gt;600GB&lt;/td&gt;
&lt;td&gt;8×H100 80GB（NVLink）&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;三关键影响因素&#34;&gt;&lt;strong&gt;三、关键影响因素&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;微调算法选择&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全参数微调&lt;/strong&gt;：显存需求最高，适合高算力集群。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LoRA/QLoRA&lt;/strong&gt;：显存需求降低 50%-90%，适合单卡训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GaLore/Freeze&lt;/strong&gt;：通过梯度压缩或参数冻结进一步优化显存。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练配置优化&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;批次大小（batch_size）&lt;/strong&gt;：增大 batch_size 会线性增加激活值显存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;梯度累积（gradient_accumulation）&lt;/strong&gt;：通过累积梯度减少单步显存需求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;量化与混合精度&lt;/strong&gt;：4-bit/8-bit 量化可降低显存 30%-70%。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分布式训练支持&lt;/strong&gt;&lt;br&gt;
LLaMA Factory 支持 DeepSpeed ZeRO 和模型并行，可将大模型拆分到多卡。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;四实战示例7b模型--qlora&#34;&gt;&lt;strong&gt;四、实战示例（7B模型 + QLoRA）&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;硬件配置&lt;/strong&gt;：RTX 4090（24GB 显存）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练命令&lt;/strong&gt;：
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;llamafactory-cli train &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --model_name_or_path meta-llama/Llama-3-8b &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --finetuning_type qlora &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --quantization_bit &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --per_device_train_batch_size &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --gradient_accumulation_steps &lt;span class=&#34;m&#34;&gt;8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;显存占用&lt;/strong&gt;：约 10-12GB（含激活值）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;五资源估算工具&#34;&gt;&lt;strong&gt;五、资源估算工具&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;LLaMA Factory 提供显存估算工具，可通过以下命令生成报告：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;llamafactory-cli estimate --model_name_or_path meta-llama/Llama-3-8b --finetuning_type lora
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如需更精确的计算，可参考 Hugging Face 的 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/transformers/v4.40.0/en/main_classes/trainer#memory-estimator&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Transformer 显存计算器&lt;/a&gt;。
&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/CJxA-PxF_lvSpMr_7uHVVg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/CJxA-PxF_lvSpMr_7uHVVg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;推理所用显存：
Total GPU Memory = 模型大小 + KV Cache + Memory Overhead
最后还是以 LLaMa-2 13B 来举例。假设有 10 个并发请求，同时请求 LLaMa-2 13B 以最大 Token数(4096) 进行模型推理。 那最终需要的 GPU Memory 计算过程如下：
模型大小= 13 Billion * 2 Bytes = 26 GB&lt;/p&gt;
&lt;p&gt;Total KV cache= 800 KB * 4096 Tokens * 10 并发请求 = 32 GB&lt;/p&gt;
&lt;p&gt;Memory Overhead= 0.1 * (26 GB + 32 GB) = 5.8 GB&lt;/p&gt;
&lt;p&gt;所以最终需要总 GPU memory为: 26 GB + 32 GB + 5.8 GB = 63.8 GB。需要 2 块英伟达的 A100 芯片才可以。
&lt;a class=&#34;link&#34; href=&#34;https://github.com/manuelescobar-dev/LLM-Tools&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/manuelescobar-dev/LLM-Tools&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@manuelescobar-dev/memory-requirements-for-llm-training-and-inference-97e4ab08091b&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://medium.com/@manuelescobar-dev/memory-requirements-for-llm-training-and-inference-97e4ab08091b&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;显存计算&#34;&gt;显存计算
&lt;/h4&gt;&lt;p&gt;推理显存评估：
$$Total\ Inference\ Memory = Model Size + KV Cache + Activations $$
模型大小：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Williamyzd/pub-imgs@main/2025-02/e21334b55e5c3e6692bf0d25103d42c561d602963061639d2981a314a86b2838.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;e21334b55e5c3e6692bf0d25103d42c561d602963061639d2981a314a86b2838&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;kv cache：
$$
KV\ Cache =2 × Batch Size × Sequence Length × Number of Layers × Hidden Size × Precision
$$
激活值：
$$
Activation Memory = Batch Size × Sequence Length × Hidden Size × ( 34 + 5 × \frac{Sequence Length ×Number of attention heads}{Hidden Size})
$$
推理显存评估：&lt;/p&gt;
&lt;p&gt;$$Total Memory=Model Size+KV Cache+Activations+(Optimizer States+Gradients)× Number of Trainable Parameters
$$
Optimizer States
Optimization algorithms require resources to store the parameters and auxiliary variables. These variables include momentum and variance used by algorithms such as Adam (2 states) or SGD (1 state). The precision and type of optimizer affect memory usage.&lt;/p&gt;
&lt;p&gt;Formula [1]&lt;/p&gt;
&lt;p&gt;AdamW (2 states): 8 Bytes per parameter
AdamW (bitsandbytes Quantized): 2 Bytes per parameter
SGD (1 state): 4 Bytes per parameter
Gradients
Gradient values are computed during the backward pass of the model. They represent the rate of change of the loss function with respect to each model parameter and are crucial for updating the parameters during optimization. As with activations, they must be stored in FP32 for numerical stability.&lt;/p&gt;
&lt;p&gt;Formula [1]&lt;/p&gt;
&lt;p&gt;4 Bytes per parameter&lt;/p&gt;
</description>
        </item>
        <item>
        <title>kind 安装k8s集群</title>
        <link>http://localhost:1313/ai/%E9%A6%96%E9%A1%B5/</link>
        <pubDate>Sat, 11 May 2024 08:38:25 +0000</pubDate>
        
        <guid>http://localhost:1313/ai/%E9%A6%96%E9%A1%B5/</guid>
        <description>&lt;h3 id=&#34;资源要求&#34;&gt;资源要求：
&lt;/h3&gt;&lt;p&gt;4C/8G&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kind.sigs.k8s.io/docs/user/known-issues/#failure-to-create-cluster-with-cgroups-v2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://kind.sigs.k8s.io/docs/user/known-issues/#failure-to-create-cluster-with-cgroups-v2&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;centos-7-在线升级内核&#34;&gt;&lt;del&gt;centos 7 在线升级内核&lt;/del&gt;
&lt;/h3&gt;&lt;p&gt;默认内核版本太低&lt;/p&gt;
&lt;p&gt;![image-20240513154841260](/Users/yangzedong/Library/Application Support/typora-user-images/image-20240513154841260.png)&lt;/p&gt;
&lt;p&gt;参考链接：https://www.cnblogs.com/liugp/p/16950443.html&lt;/p&gt;
&lt;h3 id=&#34;安装dockerkubectl&#34;&gt;安装docker/kubectl
&lt;/h3&gt;&lt;p&gt;kubectl :https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -LO &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://dl.k8s.io/release/&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl -L -s https://dl.k8s.io/release/stable.txt&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/linux/amd64/kubectl&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;docker：https://www.runoob.com/docker/centos-docker-install.html&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://get.docker.com &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; bash -s docker --mirror Aliyun
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Helm:https://helm.sh/zh/docs/intro/install/&lt;/p&gt;
&lt;h3 id=&#34;安装k8s&#34;&gt;安装k8s
&lt;/h3&gt;&lt;p&gt;参考文档：https://github.com/kubernetes-sigs/kind/tree/v0.22.0&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装kind 二进制文件&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;uname -m&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; x86_64 &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.21.0/kind-&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;uname&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;-amd64
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;*可能比较慢，可以选择手动下载安装，二进制包下载地址：https://github.com/kubernetes-sigs/kind/releases&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 执行安装操作
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x ./kind
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x ./kind
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mv ./kind /usr/local/bin/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;拉取镜像（可选）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 选一个版本
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ docker search kindest/node
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                 DESCRIPTION                           STARS     OFFICIAL
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kindest/node         https://sigs.k8s.io/kind node image   104       
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kindest/node-amd64                                         2         
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kindest/node-arm64                                         0     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 镜像拉取
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull kindest/node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装集群&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 在线创建集群
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kind create cluster
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 指定 配置文件
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# kind create cluster --config kind-example-config.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置文件地址：https://kind.sigs.k8s.io/docs/user/configuration/&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装ingress&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1. 获取yaml&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wget&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;githubusercontent&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubernetes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;deploy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;static&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;provider&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;deploy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;yaml&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2. 因服务器无外网，mac上进行下载，指定架构：一般是amd64和arm64、aarch64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# registry.k8s.io/ingress-nginx/controller:v1.10.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pull&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;platform&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;amd64&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xxx&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3. 装载image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;image&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 或者&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;archive&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;my&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;archive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;![image-20240513220418988](/Users/yangzedong/Library/Application Support/typora-user-images/image-20240513220418988.png)&lt;/p&gt;
&lt;h3 id=&#34;kind架构&#34;&gt;kind架构
&lt;/h3&gt;&lt;p&gt;参考文档：https://kind.sigs.k8s.io/docs/design/initial/&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://kind.sigs.k8s.io/docs/images/diagram.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;k8s中的端口映射&lt;/p&gt;
&lt;p&gt;参考地址：https://www.cnblogs.com/baixiaoyong/p/16051137.html&lt;/p&gt;
&lt;p&gt;k8s中的pod:https://fly-luck.github.io/2018/04/15/Kubernetes%20Ports/&lt;/p&gt;
&lt;h4 id=&#34;containerport-vs-hostport&#34;&gt;containerPort vs. hostPort
&lt;/h4&gt;&lt;p&gt;出现在如Deployment、Pod等资源对象描述文件中的容器部分，针对容器端口起类似于&lt;code&gt;docker run -p &amp;lt;containerPort&amp;gt;:&amp;lt;hostPort&amp;gt;&lt;/code&gt;的作用：
&lt;code&gt;containerPort&lt;/code&gt;：容器暴露的端口。
&lt;code&gt;hostPort&lt;/code&gt;：容器暴露的端口直接映射到的主机端口。&lt;/p&gt;
&lt;h4 id=&#34;port-vs-targetport-vs-nodeport&#34;&gt;port vs. targetPort vs. nodePort
&lt;/h4&gt;&lt;p&gt;出现在Service描述文件中，当Service的类型为&lt;code&gt;ClusterIP&lt;/code&gt;时：
&lt;code&gt;port&lt;/code&gt;：Service中ClusterIP对应的端口。
&lt;code&gt;targetport&lt;/code&gt;：clusterIP作为负载均衡， 后端目标实例（容器）的端口，与上述&lt;code&gt;containerPort&lt;/code&gt;保持一致。&lt;/p&gt;
&lt;p&gt;当Service的类型为&lt;code&gt;NodePort&lt;/code&gt;时：
&lt;code&gt;nodePort&lt;/code&gt;：由于ClusterIP只能集群内访问，配置nodePort会在每个运行&lt;code&gt;kubelet&lt;/code&gt;节点的宿主机打开一个端口，用于集群外部访问。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Kubeflow 安装</title>
        <link>http://localhost:1313/ai/kubeflow%E5%AE%89%E8%A3%85/</link>
        <pubDate>Sat, 11 May 2024 08:38:25 +0000</pubDate>
        
        <guid>http://localhost:1313/ai/kubeflow%E5%AE%89%E8%A3%85/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq836825331/article/details/136846624&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/qq836825331/article/details/136846624&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;下载镜像&#34;&gt;下载镜像
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Kustomize安装&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -s &amp;#34;https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh&amp;#34;  | bash
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x kustomize &amp;amp;&amp;amp; mv kustomize /usr/local/bin/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;下载镜像&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://github.com/kubeflow/manifests/archive/refs/tags/v1.8.1.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -zxvf v1.8.1.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cd v1.8.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 过滤出镜像，注意需要手动做下排查
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kustomize build example |grep &amp;#39;image: &amp;#39;|awk &amp;#39;$2 != &amp;#34;&amp;#34; { print $2}&amp;#39; |sort -u 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 下载镜像，并push到dockerhub
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;#34;for i in `cat images.txt`; do docker pull $i ;tag_w=`echo &amp;#34;$i&amp;#34; | sed &amp;#39;s/\//_/g&amp;#39;`;tag_new=&amp;#34;williamyang1/kubeflow_$tag_w&amp;#34;;docker tag $i  $tag_new ;docker push $tag_new ;docker rmi $tag_new $i;echo &amp;#34;$tag_new&amp;#34; &amp;gt;&amp;gt; n_images.txt; done&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最终的镜像列表&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/busybox:1.28
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_istio_pilot:1.17.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_istio_proxyv2:1.17.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_earlystopping-medianstop:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_enas-cnn-cifar10-cpu:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_file-metrics-collector:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_katib-controller:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_katib-db-manager:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_katib-ui:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_mxnet-mnist:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_pytorch-mnist-cpu:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-darts:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-enas:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-goptuna:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-hyperband:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-hyperopt:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-optuna:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-pbt:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_suggestion-skopt:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowkatib_tfevent-metrics-collector:v0.16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflowmanifestswg_oidc-authservice:e236439
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_centraldashboard:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_jupyter-web-app:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_kfam:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_notebook-controller:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_poddefaults-webhook:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_profile-controller:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_pvcviewer-controller:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_tensorboard-controller:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_tensorboards-web-app:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_kubeflownotebookswg_volumes-web-app:v1.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_metacontrollerio_metacontroller:v2.0.4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/docker.io_seldonio_mlserver:1.3.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_controller@sha256:92967bab4ad8f7d55ce3a77ba8868f3f2ce173c010958c28b9a690964ad6ee9b
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_mtping@sha256:6d35cc98baa098fc0c5b4290859e363a8350a9dadc31d1191b0b5c9796958223
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_webhook@sha256:ebf93652f0254ac56600bedf4a7d81611b3e1e7f6526c6998da5dd24cdc67ee1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_net-istio_cmd_controller@sha256:421aa67057240fa0c56ebf2c6e5b482a12842005805c46e067129402d1751220
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_net-istio_cmd_webhook@sha256:bfa1dfea77aff6dfa7959f4822d8e61c4f7933053874cd3f27352323e6ecd985
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_activator@sha256:c2994c2b6c2c7f38ad1b85c71789bf1753cc8979926423c83231e62258837cb9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_autoscaler@sha256:8319aa662b4912e8175018bd7cc90c63838562a27515197b803bdcd5634c7007
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_controller@sha256:98a2cc7fd62ee95e137116504e7166c32c65efef42c3d1454630780410abf943
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_domain-mapping@sha256:f66c41ad7a73f5d4f4bdfec4294d5459c477f09f3ce52934d1a215e32316b59b
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_domain-mapping-webhook@sha256:7368aaddf2be8d8784dc7195f5bc272ecfe49d429697f48de0ddc44f278167aa
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_queue@sha256:dabaecec38860ca4c972e6821d5dc825549faf50c6feb8feb4c04802f2338b8a
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_webhook@sha256:4305209ce498caf783f39c8f3e85dfa635ece6947033bf50b0b627983fd65953
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_kubebuilder_kube-rbac-proxy:v0.13.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_kubebuilder_kube-rbac-proxy:v0.8.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_api-server:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_cache-server:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_frontend
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_frontend:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_metadata-writer:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_minio:RELEASE.2019-08-14T20-37-41Z-license-compliance
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_mysql:8.0.26
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_persistenceagent:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_scheduledworkflow:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_viewer-crd-controller:2.0.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_visualization-server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_ml-pipeline_workflow-controller:v3.3.10-license-compliance
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/gcr.io_tfx-oss-public_ml_metadata_store_server:1.14.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/ghcr.io_dexidp_dex:v2.36.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_kserve-controller:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_lgbserver:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_models-web-app:v0.10.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_paddleserver:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_pmmlserver:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_sklearnserver:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kserve_xgbserver:v0.11.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/kubeflow_training-operator:v1-855e096
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/mysql:8.0.29
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/nvcr.io_nvidia_tritonserver:23.05-py3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/python:3.7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/pytorch_torchserve-kfs:0.8.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/quay.io_jetstack_cert-manager-cainjector:v1.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/quay.io_jetstack_cert-manager-controller:v1.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/quay.io_jetstack_cert-manager-webhook:v1.12.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;williamyang1/tensorflow_serving:2.6.2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;安装k8s&#34;&gt;安装k8s
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Kubesphere 安装k8s&amp;ndash;v1.27.10&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubesphere.io/zh/docs/v3.4/quick-start/all-in-one-on-linux/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://kubesphere.io/zh/docs/v3.4/quick-start/all-in-one-on-linux/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubesphere.io/zh/blogs/using-kubekey-deploy-k8s-v1.28.8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://kubesphere.io/zh/blogs/using-kubekey-deploy-k8s-v1.28.8/&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装基础软件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;yum&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;socat&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conntrack&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ebtables&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ipset&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ipvsadm&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装工具&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# shell安装 或者离线下载&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sfL&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;io&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;sh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## 离线下载&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubekey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;releases&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubekey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amd64&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chmod&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mv&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;usr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;local&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 确认是否包含想要安装的版本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;version&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;supported&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k8s&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建manifest 导出供离线下载使用&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;manifest&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubernetes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;27&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 下载基础环境镜像-manifest用到的工具，单独下载--可选&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 镜像所在地址&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubekey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;releases&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 找一台访问速度快的机器下载&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kubekey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;releases&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;centos7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rpms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amd64&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iso&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 这一步骤会下载manifest-sample.yaml中涉及的的工具如kubelet/containerd/helm等&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;artifact&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;manifest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;yaml&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;o&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 此步骤为方便没有外网的机器创建集群。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cluster&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;yaml&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kubesphere&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;packages&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;安装kubeflow&#34;&gt;安装kubeflow
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubeflow/manifests&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/kubeflow/manifests&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 下载镜像
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;for i in `cat images.txt`; do ctr imgaes pull $i ;done
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>地理信息可视化</title>
        <link>http://localhost:1313/ai/%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E5%8F%AF%E8%A7%86%E5%8C%96/</link>
        <pubDate>Sat, 11 May 2024 08:38:25 +0000</pubDate>
        
        <guid>http://localhost:1313/ai/%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E5%8F%AF%E8%A7%86%E5%8C%96/</guid>
        <description>&lt;p&gt;参考文献：https://www.jianshu.com/p/d78fff321005&lt;/p&gt;
&lt;h2 id=&#34;数据存储格式wkt-vs-geojson&#34;&gt;数据存储格式：WKT VS GeoJSON
&lt;/h2&gt;&lt;h3 id=&#34;wkt是什么&#34;&gt;WKT是什么？
&lt;/h3&gt;&lt;p&gt;WKT(well-know text)是开放地理空间联盟OGC制定的一种文本标记语言，用于表示矢量几何对象、空间参照系统及空间参照系统之间的转换。&lt;/p&gt;
&lt;h3 id=&#34;wkb是什么&#34;&gt;WKB是什么？
&lt;/h3&gt;&lt;p&gt;WKB(well-know binary)是WKT的二进制表现形式，解决WKT表达冗余的问题，便于传输和存储在数据库中。&lt;/p&gt;
&lt;h3 id=&#34;geojson是什么&#34;&gt;GeoJSON是什么？
&lt;/h3&gt;&lt;p&gt;以JSON的格式输出空间数据，便于被javascript等脚本调用。&lt;/p&gt;
&lt;h3 id=&#34;wkt与geojson&#34;&gt;WKT与GeoJSON
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;WKT与GeoJSON分为点、线、面、几何集合四种：&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;点&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;线&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;面&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;组合&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Point   MultiPoint&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;LineString   MultiLineString&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Polygon   MultiPolygon&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;GeometryCollection&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;类型&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;WKT&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;GeoJSON&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Point&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;POINT(10 10)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;Point&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;: [10, 10] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;LineString&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;LINESTRING(10 10, 20 30)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;Point&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;:[ [10, 10], [20, 30] ] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Polygon&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;POLYGON(10 10, 15 16, 22 10, 30 32)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;Polygon&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;: [ [ [10, 10], [10, 10], [10, 10], [10, 10] ] ] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MultiPoint&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MULTIPOINT(*)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;MultiPoint&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;: [*] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MultiLineString&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MULTILINESTRING (*)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;MultiLineString&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;: [*] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MultiPolygon&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;MULTIPOLYGON (*)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;{ &amp;ldquo;type&amp;rdquo;:  &amp;ldquo;MultiPolygon&amp;rdquo;, &amp;ldquo;coordinates&amp;rdquo;: [*] }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;GEOMETRYCOLLECTION&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;GEOMETRYCOLLECTION(POINT(2 3),LINESTRING(2 3,3 4))&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;WKT与GeoJSON的区别
WKT是用来单独表示空间点、线、面数据，GeoJSON还可以用来表示空间数据和属性数据的集合  （crs、bbox属性）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用geopandas-读取-wkt字符串数据&#34;&gt;使用GeoPandas 读取 wkt字符串数据
&lt;/h3&gt;&lt;p&gt;获取山东省地图土地轮廓并使用GeoPandas加载展示&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过百度地图api获取数据信息&lt;/li&gt;
&lt;li&gt;将形状字符串转换为MultiPolygon类型数据&lt;/li&gt;
&lt;li&gt;通过GeoPandas加载数据&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# encoding:utf-8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 根据您选择的AK已为您生成调用代码
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 检测到您当前的AK设置了IP白名单校验
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 您的IP白名单中的IP非公网IP，请设置为公网IP，否则将请求失败
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 请在IP地址为0.0.0.0/0 外网IP的计算发起请求，否则将请求失败
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;import requests 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sds =None
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 服务地址
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;host = &amp;#34;https://api.map.baidu.com&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 接口地址
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uri = &amp;#34;/api_region_search/v1/&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 此处填写你在控制台-应用管理-创建应用后获取的AK
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ak = &amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;params = {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;keyword&amp;#34;:    &amp;#34;山东省&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;sub_admin&amp;#34;:    &amp;#34;0&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;ak&amp;#34;:       ak,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;extensions_code&amp;#34;:1,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;boundary&amp;#34;:1,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;response = requests.get(url = host + uri, params = params)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sds =None
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;if response:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # print(response.json())
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    sds = response.json()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    print(sds[&amp;#39;districts&amp;#39;])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# pd.DataFrame(sds[&amp;#39;districts&amp;#39;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
