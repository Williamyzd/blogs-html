[{"content":"摘要： 搭建个人博客\u0026ndash;基于hugo\n基本思路：\n使用在本地编辑Markdown文档，并测试预览。成功后推送到github私有仓库。在vps中运行一个nginx容器，定时拉取github中的文件并对外展示。hugo可以将markdown文档渲染为html文件，在nginx容器中，也只需对外暴漏渲染后的nginx文件即可。\n本地编辑环境搭建 二进制安装hugo 直接安装二进制文件，可参考：https://github.com/gohugoio/hugo/releases 下载对应版本并安装 以mac客户端为例，下载对应版本后解压到指定目录。\n1 2 3 4 5 6 7 # 文件解压 tar -zxvf hugo_0.143.0_darwin-universal.tar.gz cd hugo_0.143.0_darwin-universal chmod +x hugo mv hugo /usr/local/bin # 验证测试 hugo version 源码安装hugo 如需源码安装，以mac客户端为例，需要安装git、hugo。\n安装git mac自带git，无需安装。如需安装或更新，可参考：https://git-scm.com/downloads/mac\n安装go 可参考链接：https://go.dev/dl/选择对应版本的hugo，下载后解压到指定目录。\n安装hugo go install github.com/gohugoio/hugo@latest\n配置ssh key 克隆主题仓库到本地 修改主题样式 本地调试 远程部署 制作基础镜像 设置git定时任务 参考链接：\n博客搭建：https://gohugo.io/getting-started/quick-start/ ssh设置：https://docs.github.com/zh/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account ","date":"2024-05-16T02:54:56+08:00","permalink":"http://localhost:1313/ops/%E6%90%AD%E5%BB%BAhugo%E5%8D%9A%E5%AE%A2/","title":"搭建个人博客--基于hugo"},{"content":"摘要: 本文详细介绍了Linux Volume Manager (LVM) 的相关命令，包括磁盘分区、物理卷创建、卷组管理、逻辑卷创建与管理、文件系统挂载与自动挂载等步骤。LVM 是一种逻辑卷管理技术，允许用户在物理磁盘上创建、扩展、缩减和移动分区，而不必重新分区或重新格式化磁盘。通过LVM，可以更灵活地管理存储空间，提高存储利用率和灵活性。\n参考链接：https://support.huaweicloud.com/bestpractice-evs/evs_02_0002.html\n磁盘分区 新挂载硬盘或者扩充硬盘\nparted相关命令 按照如下命令建立分区、文件系统格式、打上lvm标签\n1 2 3 4 5 6 7 8 9 lsblk # 查看挂载磁盘 parted /dev/vdd # 回车后按照以下操作： mklabel gpt # 大于2T以上磁盘使用该格式 mkpart p1 ext4 0 100GB # p1 分区名称,ext4 文件系统格式 0 起始位置（百分比or数字），100GB结束位置（百分比or数字） print #查看分区结果 toggle 3 lvm # 3 新创建分区的编号，lvm 标签，从而可以使用lvm来管理 quit # 退出parted命令 lsblk #查看分区情况 通过新增磁盘来创建物理卷 pvcreate /dev/vdd3\n物理卷 查看磁盘 1 2 3 fdisk -l | grep /dev/vd | grep -v vda Disk /dev/vdb: 10.7 GB, 10737418240 bytes, 20971520 sectors Disk /dev/vdc: 10.7 GB, 10737418240 bytes, 20971520 sectors 执行以下命令，将云硬盘创建为物理卷。 pvcreate 磁盘设备名1 磁盘设备名2 磁盘设备名3\n参数说明如下：\n磁盘设备名：此处需要填写磁盘的设备名称，如果需要批量创建，可以填写多个设备名称，中间以空格间隔。\n命令示例:\npvcreate /dev/vdb /dev/vdc\n1 2 3 pvcreate /dev/vdb /dev/vdc Physical volume \u0026#34;/dev/vdb\u0026#34; successfully created. Physical volume \u0026#34;/dev/vdc\u0026#34; successfully created. 执行如下命令，查看系统中物理卷的详细信息。 pvdisplay\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 pvdisplay \u0026#34;/dev/vdc\u0026#34; is a new physical volume of \u0026#34;10.00 GiB\u0026#34; --- NEW Physical volume --- PV Name /dev/vdc VG Name PV Size 10.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID dypyLh-xjIj-PvG3-jD0j-yup5-O7SI-462R7C \u0026#34;/dev/vdb\u0026#34; is a new physical volume of \u0026#34;10.00 GiB\u0026#34; --- NEW Physical volume --- PV Name /dev/vdb VG Name PV Size 10.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID srv5H1-tgLu-GRTl-Vns8-GfNK-jtHk-Ag4HHB 卷组 创建卷组 执行以下命令，创建卷组。 vgcreate 卷组名 物理卷名称1 物理卷名称2 物理卷名称3\u0026hellip;\n参数说明如下：\n​\t卷组名：可自定义，此处以vgdata为例。\n​\t物理卷名称：此处需要填写待添加进卷组的所有物理卷名称，中间以空格隔开。\n命令示例:\nvgcreate vgdata /dev/vdb /dev/vdc\n回显类似如下信息：\n1 2 vgcreate vgdata /dev/vdb /dev/vdc Volume group \u0026#34;vgdata\u0026#34; successfully created 执行如下命令，查看系统中卷组的详细信息。 vgdisplay\n卷组扩/缩容 查看磁盘，并如创建物理卷\nfdisk -l | grep /dev/vd | grep -v vda\npvcreate 磁盘**设备名\n添加新的物理卷\nvgextend 卷组名称 物理卷名称\n命令示例:\nvgextend vgdata /dev/vdd\n删除物理卷\nvgreduce 卷组名称 物理卷名称\n命令示例:\nvgreduce vgdata /dev/vdd\n逻辑卷 创建逻辑卷 lvcreate** -L 逻辑卷大小 -n 逻辑卷名称 卷组名称 参数说明如下：\n逻辑卷大小：该值应小于卷组剩余可用空间大小，单位可以选择“MB”或“GB”。\n逻辑卷名称：可自定义，此处以lvdata1为例。\n卷组名称：此处需要填写逻辑卷所在的卷组名称。\n命令示例:\nlvcreate -L 15GB -n lvdata1 vgdata\n1 2 lvcreate -L 15GB -n lvdata1 vgdata Logical volume \u0026#34;lvdata1\u0026#34; created. 执行如下命令，查询系统中逻辑卷的详细信息。\nlvdisplay\n扩充逻辑卷 执行如下命令，扩展逻辑卷的容量。 lvextend -L +增加容量 逻辑卷路径\n参数说明如下：\n增加容量：该值应小于组卷剩余可用空间大小，单位可以选择“MB”或“GB”。\n逻辑卷路径：此处需要填写待扩容的逻辑卷的路径。\n命令示例: lvextend -L +4GB /dev/vgdata/lvdata1\n回显类似如下信息：\n1 2 lvextend -L +4GB /dev/vgdata/lvdata1 Size of logical volume vgdata/lvdata1 changed from 15.00 GiB (3840 extents) to 19.00 GiB (4864 extents). Logical volume vgdata/lvdata1 successfully resized. 此时只是扩展的逻辑卷的容量，在其之上的文件系统也要随之进行扩展才能使用。\n执行如下命令，扩展文件系统的容量。\nresize2fs 逻辑卷路径\n命令示例: resize2fs /dev/vgdata/lvdata1\n回显类似如下信息：\n1 2 resize2fs /dev/vgdata/lvdata1 resize2fs 1.42.9 (28-Dec-2013) Filesystem at /dev/vgdata/lvdata1 is mounted on /Data1; on-line resizing required old_desc_blocks = 4, new_desc_blocks = 28 The filesystem on /dev/vgdata/lvdata1 is now 3657728 blocks long. 执行如下命令，查看文件系统容量是否增加。\ndf -h 回显类似如下信息：\n1 2 3 4 5 6 7 8 9 10 df -h Filesystem Size Used Avail Use% Mounted on /dev/vda2 39G 1.5G 35G 5% / devtmpfs 487M 0 487M 0% /dev tmpfs 496M 0 496M 0% /dev/shm tmpfs 496M 6.7M 490M 2% /run tmpfs 496M 0 496M 0% /sys/fs/cgroup /dev/vda1 976M 131M 779M 15% /boot tmpfs 100M 0 100M 0% /run/user/0 /dev/mapper/vgdata-lvdata1 19G 44M 18G 1% /Data1 可以看到，文件系统“/dev/mapper/vgdata-lvdata1”的容量相比之前增加了4GB。\n逻辑卷缩容 不可在线操作，需要先umount 挂载\n主要命令\numount /Data1 # /data1为挂载路径 e2fsck -f /dev/vgdata/lvdata1 # 进行磁盘检查 resize2fs /dev/vgdata/lvdata1 1G # 调整文件系统 lvreduce -L 1GB /dev/vgdata/lvdata # 通过lvduce命令进行缩 mount /dev/vgdata/lvdata1 /Data1 # 重新挂载 1 2 3 4 5 6 7 8 9 10 umount /Data1 # /data1为挂载路径 mount |grep Data1|wc -l # 查看是否成功卸载 lvs |grep Data1 # 查看磁盘状态 e2fsck -f /dev/vgdata/lvdata1 # 进行磁盘检查 resize2fs /dev/vgdata/lvdata1 1G # 调整文件系统 lvs |grep Data1 # 查看磁盘状态，未发生变化 lvreduce -L 1GB /dev/vgdata/lvdata # 通过lvduce命令进行缩 lvs |grep Data1 # 查看磁盘状态，可发现减少 mount /dev/vgdata/lvdata1 /Data1 # 重新挂载 df -lh |grep Data1 # 查看当前状态 挂载文件系统 执行如下命令，创建文件系统。 **mkfs.**文件格式 逻辑卷路径\n命令示例:\nmkfs.ext4 /dev/vgdata/lvdata1\n回显类似如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 mkfs.ext4 /dev/vgdata/lvdata1 mke2fs 1.42.9 (28-Dec-2013) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 983040 inodes, 3932160 blocks 196608 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=2151677952 120 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done 手动挂载 具备文件系统后才可以挂载\n创建挂载目录。 mkdir 挂载目录 命令示例: mkdir /Data1 执行如下命令，将文件系统挂载到目录下。 mount 逻辑卷路径 挂载目录 命令示例： mount /dev/vgdata/lvdata1 /Data1 执行如下命令，查询文件系统挂载信息。 mount | grep 挂载目录 命令示例： mount | grep /Data1 ​\t回显类似如下信息：\n1 2 mount | grep /Data1 /dev/mapper/vgdata-lvdata1 on /Data1 type ext4 (rw,relatime,data=ordered) 开机自动挂载 执行以下步骤，设置云服务器系统启动时自动挂载文件系统。\n执行如下命令，查询文件系统的UUID。\nblkid 文件系统路径\n以查询“dev/mapper/vgdata-lvdata1”的UUID为例：\nblkid /dev/mapper/vgdata-lvdata1\n1 2 blkid /dev/mapper/vgdata-lvdata1 /dev/mapper/vgdata-lvdata1: UUID=\u0026#34;c6a243ce-5150-41ac-8816-39db54d1a4b8\u0026#34; TYPE=\u0026#34;ext4\u0026#34; 执行以下命令，打开“/etc/fstab”文件。\nvi /etc/fstab\n1 2 3 4 5 6 7 8 9 10 11 vi /etc/fstab # # /etc/fstab # Created by anaconda on Tue Nov 7 14:28:26 2017 # # Accessible filesystems, by reference, are maintained under \u0026#39;/dev/disk\u0026#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=27f9be47-838b-4155-b20b-e4c5e013cdf3 / ext4 defaults 1 1 UUID=2b2000b1-f926-4b6b-ade8-695ee244a901 /boot ext4 defaults 1 2 按“i”进入编辑模式，将光标移至文件末尾，按“Enter”，添加如下内容。\n1 UUID=c6a243ce-5150-41ac-8816-39db54d1a4b8 /Data1 ext4 defaults 0 0 内容说明如下：\n第一列：UUID，此处填写1查询的UUID；\n第二列：文件系统的挂载目录；\n第三列：文件系统的文件格式，如文件格式“ext4”;\n第四列：挂载选项，此处以“defaults”为例；\n第五列：备份选项，设置为“1”时，系统自动对该文件系统进行备份；设置为“0”时，不进行备份。此处以“0”为例；\n第六列：扫描选项，设置为“1”时，系统在启动时自动对该文件系统进行扫描；设置为“0”时，不进行扫描。此处以“0”为例。\n按“Esc”，输入“:wq!”，并按“Enter”。保存设置并退出vi编辑器。\n执行以下步骤，验证自动挂载功能\n执行如下命令，卸载文件系统。\numount 逻辑卷路径\n命令示例： umount /dev/vgdata/lvdata1\n执行如下命令，将/etc/fstab文件所有内容重新加载。\nmount -a\n执行如下命令，查询文件系统挂载信息。\nmount | grep 挂载目录\n命令示例： mount | grep /Data1\n回显类似如下信息，说明自动挂载功能生效：\n1 2 mount | grep /Data1 /dev/mapper/vgdata-lvdata1 on /Data1 type ext4 (rw,relatime,data=ordered) ​\n","date":"2024-05-11T08:38:47Z","permalink":"http://localhost:1313/ops/lvm%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/","title":"LVM相关命令"},{"content":"https://qwen.readthedocs.io/zh-cn/latest/getting_started/quickstart.html\nhttps://github.com/QwenLM/Qwen2?tab=readme-ov-file\nhttps://github.com/datawhalechina/llm-universe\nhttps://github.com/datawhalechina/self-llm\n","date":"2024-05-11T08:38:47Z","permalink":"http://localhost:1313/cs/%E9%80%9A%E4%B9%89%E5%8D%83%E9%97%AE%E7%A7%81%E6%9C%89%E5%8C%96%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3/","title":"通义千问私有化部署文档"},{"content":"资源要求： 4C/8G\nhttps://kind.sigs.k8s.io/docs/user/known-issues/#failure-to-create-cluster-with-cgroups-v2\ncentos 7 在线升级内核 默认内核版本太低\n![image-20240513154841260](/Users/yangzedong/Library/Application Support/typora-user-images/image-20240513154841260.png)\n参考链接：https://www.cnblogs.com/liugp/p/16950443.html\n安装docker/kubectl kubectl :https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/\n1 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; docker：https://www.runoob.com/docker/centos-docker-install.html\n1 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun Helm:https://helm.sh/zh/docs/intro/install/\n安装k8s 参考文档：https://github.com/kubernetes-sigs/kind/tree/v0.22.0\n安装kind 二进制文件\n1 [ $(uname -m) = x86_64 ] \u0026amp;\u0026amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.21.0/kind-$(uname)-amd64 *可能比较慢，可以选择手动下载安装，二进制包下载地址：https://github.com/kubernetes-sigs/kind/releases\n1 2 3 4 # 执行安装操作 chmod +x ./kind chmod +x ./kind mv ./kind /usr/local/bin/ 拉取镜像（可选）\n1 2 3 4 5 6 7 8 # 选一个版本 $ docker search kindest/node NAME DESCRIPTION STARS OFFICIAL kindest/node https://sigs.k8s.io/kind node image 104 kindest/node-amd64 2 kindest/node-arm64 0 # 镜像拉取 docker pull kindest/node 安装集群\n1 2 3 4 # 在线创建集群 kind create cluster # 指定 配置文件 # kind create cluster --config kind-example-config.yaml 配置文件地址：https://kind.sigs.k8s.io/docs/user/configuration/\n安装ingress\n1 2 3 4 5 6 7 8 9 10 11 # 1. 获取yaml wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml # 2. 因服务器无外网，mac上进行下载，指定架构：一般是amd64和arm64、aarch64 # registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1 # registry.k8s.io/ingress-nginx/controller:v1.10.1 # registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1 docker pull --platform amd64 xxx # 3. 装载image kind load docker-image img:v1 # 或者 kind load image-archive my-image-archive.tar ![image-20240513220418988](/Users/yangzedong/Library/Application Support/typora-user-images/image-20240513220418988.png)\nkind架构 参考文档：https://kind.sigs.k8s.io/docs/design/initial/\nk8s中的端口映射\n参考地址：https://www.cnblogs.com/baixiaoyong/p/16051137.html\nk8s中的pod:https://fly-luck.github.io/2018/04/15/Kubernetes%20Ports/\ncontainerPort vs. hostPort 出现在如Deployment、Pod等资源对象描述文件中的容器部分，针对容器端口起类似于docker run -p \u0026lt;containerPort\u0026gt;:\u0026lt;hostPort\u0026gt;的作用： containerPort：容器暴露的端口。 hostPort：容器暴露的端口直接映射到的主机端口。\nport vs. targetPort vs. nodePort 出现在Service描述文件中，当Service的类型为ClusterIP时： port：Service中ClusterIP对应的端口。 targetport：clusterIP作为负载均衡， 后端目标实例（容器）的端口，与上述containerPort保持一致。\n当Service的类型为NodePort时： nodePort：由于ClusterIP只能集群内访问，配置nodePort会在每个运行kubelet节点的宿主机打开一个端口，用于集群外部访问。\n","date":"2024-05-11T08:38:25Z","permalink":"http://localhost:1313/ai/%E9%A6%96%E9%A1%B5/","title":"kind 安装k8s集群"},{"content":"https://blog.csdn.net/qq836825331/article/details/136846624\n下载镜像 Kustomize安装 1 2 curl -s \u0026#34;https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh\u0026#34; | bash chmod +x kustomize \u0026amp;\u0026amp; mv kustomize /usr/local/bin/ 下载镜像 1 2 3 4 5 6 7 wget https://github.com/kubeflow/manifests/archive/refs/tags/v1.8.1.tar.gz tar -zxvf v1.8.1.tar.gz cd v1.8.1 # 过滤出镜像，注意需要手动做下排查 kustomize build example |grep \u0026#39;image: \u0026#39;|awk \u0026#39;$2 != \u0026#34;\u0026#34; { print $2}\u0026#39; |sort -u # 下载镜像，并push到dockerhub \u0026#34;for i in `cat images.txt`; do docker pull $i ;tag_w=`echo \u0026#34;$i\u0026#34; | sed \u0026#39;s/\\//_/g\u0026#39;`;tag_new=\u0026#34;williamyang1/kubeflow_$tag_w\u0026#34;;docker tag $i $tag_new ;docker push $tag_new ;docker rmi $tag_new $i;echo \u0026#34;$tag_new\u0026#34; \u0026gt;\u0026gt; n_images.txt; done\u0026#34; 最终的镜像列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 williamyang1/busybox:1.28 williamyang1/docker.io_istio_pilot:1.17.5 williamyang1/docker.io_istio_proxyv2:1.17.5 williamyang1/docker.io_kubeflowkatib_earlystopping-medianstop:v0.16.0 williamyang1/docker.io_kubeflowkatib_enas-cnn-cifar10-cpu:v0.16.0 williamyang1/docker.io_kubeflowkatib_file-metrics-collector:v0.16.0 williamyang1/docker.io_kubeflowkatib_katib-controller:v0.16.0 williamyang1/docker.io_kubeflowkatib_katib-db-manager:v0.16.0 williamyang1/docker.io_kubeflowkatib_katib-ui:v0.16.0 williamyang1/docker.io_kubeflowkatib_mxnet-mnist:v0.16.0 williamyang1/docker.io_kubeflowkatib_pytorch-mnist-cpu:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-darts:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-enas:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-goptuna:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-hyperband:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-hyperopt:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-optuna:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-pbt:v0.16.0 williamyang1/docker.io_kubeflowkatib_suggestion-skopt:v0.16.0 williamyang1/docker.io_kubeflowkatib_tfevent-metrics-collector:v0.16.0 williamyang1/docker.io_kubeflowmanifestswg_oidc-authservice:e236439 williamyang1/docker.io_kubeflownotebookswg_centraldashboard:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_jupyter-web-app:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_kfam:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_notebook-controller:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_poddefaults-webhook:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_profile-controller:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_pvcviewer-controller:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_tensorboard-controller:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_tensorboards-web-app:v1.8.0 williamyang1/docker.io_kubeflownotebookswg_volumes-web-app:v1.8.0 williamyang1/docker.io_metacontrollerio_metacontroller:v2.0.4 williamyang1/docker.io_seldonio_mlserver:1.3.2 williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_controller@sha256:92967bab4ad8f7d55ce3a77ba8868f3f2ce173c010958c28b9a690964ad6ee9b williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_mtping@sha256:6d35cc98baa098fc0c5b4290859e363a8350a9dadc31d1191b0b5c9796958223 williamyang1/gcr.io_knative-releases_knative.dev_eventing_cmd_webhook@sha256:ebf93652f0254ac56600bedf4a7d81611b3e1e7f6526c6998da5dd24cdc67ee1 williamyang1/gcr.io_knative-releases_knative.dev_net-istio_cmd_controller@sha256:421aa67057240fa0c56ebf2c6e5b482a12842005805c46e067129402d1751220 williamyang1/gcr.io_knative-releases_knative.dev_net-istio_cmd_webhook@sha256:bfa1dfea77aff6dfa7959f4822d8e61c4f7933053874cd3f27352323e6ecd985 williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_activator@sha256:c2994c2b6c2c7f38ad1b85c71789bf1753cc8979926423c83231e62258837cb9 williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_autoscaler@sha256:8319aa662b4912e8175018bd7cc90c63838562a27515197b803bdcd5634c7007 williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_controller@sha256:98a2cc7fd62ee95e137116504e7166c32c65efef42c3d1454630780410abf943 williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_domain-mapping@sha256:f66c41ad7a73f5d4f4bdfec4294d5459c477f09f3ce52934d1a215e32316b59b williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_domain-mapping-webhook@sha256:7368aaddf2be8d8784dc7195f5bc272ecfe49d429697f48de0ddc44f278167aa williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_queue@sha256:dabaecec38860ca4c972e6821d5dc825549faf50c6feb8feb4c04802f2338b8a williamyang1/gcr.io_knative-releases_knative.dev_serving_cmd_webhook@sha256:4305209ce498caf783f39c8f3e85dfa635ece6947033bf50b0b627983fd65953 williamyang1/gcr.io_kubebuilder_kube-rbac-proxy:v0.13.1 williamyang1/gcr.io_kubebuilder_kube-rbac-proxy:v0.8.0 williamyang1/gcr.io_ml-pipeline_api-server:2.0.5 williamyang1/gcr.io_ml-pipeline_cache-server:2.0.5 williamyang1/gcr.io_ml-pipeline_frontend williamyang1/gcr.io_ml-pipeline_frontend:2.0.5 williamyang1/gcr.io_ml-pipeline_metadata-writer:2.0.5 williamyang1/gcr.io_ml-pipeline_minio:RELEASE.2019-08-14T20-37-41Z-license-compliance williamyang1/gcr.io_ml-pipeline_mysql:8.0.26 williamyang1/gcr.io_ml-pipeline_persistenceagent:2.0.5 williamyang1/gcr.io_ml-pipeline_scheduledworkflow:2.0.5 williamyang1/gcr.io_ml-pipeline_viewer-crd-controller:2.0.5 williamyang1/gcr.io_ml-pipeline_visualization-server williamyang1/gcr.io_ml-pipeline_workflow-controller:v3.3.10-license-compliance williamyang1/gcr.io_tfx-oss-public_ml_metadata_store_server:1.14.0 williamyang1/ghcr.io_dexidp_dex:v2.36.0 williamyang1/kserve_kserve-controller:v0.11.2 williamyang1/kserve_lgbserver:v0.11.2 williamyang1/kserve_models-web-app:v0.10.0 williamyang1/kserve_paddleserver:v0.11.2 williamyang1/kserve_pmmlserver:v0.11.2 williamyang1/kserve_sklearnserver:v0.11.2 williamyang1/kserve_xgbserver:v0.11.2 williamyang1/kubeflow_training-operator:v1-855e096 williamyang1/mysql:8.0.29 williamyang1/nvcr.io_nvidia_tritonserver:23.05-py3 williamyang1/python:3.7 williamyang1/pytorch_torchserve-kfs:0.8.2 williamyang1/quay.io_jetstack_cert-manager-cainjector:v1.12.2 williamyang1/quay.io_jetstack_cert-manager-controller:v1.12.2 williamyang1/quay.io_jetstack_cert-manager-webhook:v1.12.2 williamyang1/tensorflow_serving:2.6.2 安装k8s Kubesphere 安装k8s\u0026ndash;v1.27.10 https://kubesphere.io/zh/docs/v3.4/quick-start/all-in-one-on-linux/\nhttps://kubesphere.io/zh/blogs/using-kubekey-deploy-k8s-v1.28.8/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 安装基础软件 yum install -y socat conntrack ebtables ipset ipvsadm # 安装工具 # shell安装 或者离线下载 curl -sfL https://get-kk.kubesphere.io | sh - ## 离线下载 https://github.com/kubesphere/kubekey/releases/download/v3.1.1/kubekey-v3.1.1-linux-amd64.tar.gz chmod +x kk mv kk /usr/local/bin/ # 确认是否包含想要安装的版本 kk version --show-supported-k8s # 创建manifest 导出供离线下载使用 kk create manifest --with-kubernetes v1.27 # 下载基础环境镜像-manifest用到的工具，单独下载--可选 # 镜像所在地址 https://github.com/kubesphere/kubekey/releases/tag/v3.1.1 # 找一台访问速度快的机器下载 https://github.com/kubesphere/kubekey/releases/download/v3.1.1/centos7-rpms-amd64.iso # 这一步骤会下载manifest-sample.yaml中涉及的的工具如kubelet/containerd/helm等 ./kk artifact export -m manifest-sample.yaml -o kubesphere.tar.gz # 此步骤为方便没有外网的机器创建集群。 ./kk create cluster -f config-sample.yaml -a kubesphere.tar.gz --with-packages 安装kubeflow https://github.com/kubeflow/manifests\n1 2 # 下载镜像 for i in `cat images.txt`; do ctr imgaes pull $i ;done ","date":"2024-05-11T08:38:25Z","permalink":"http://localhost:1313/ai/kubeflow%E5%AE%89%E8%A3%85/","title":"Kubeflow 安装"},{"content":"参考文献：https://www.jianshu.com/p/d78fff321005\n数据存储格式：WKT VS GeoJSON WKT是什么？ WKT(well-know text)是开放地理空间联盟OGC制定的一种文本标记语言，用于表示矢量几何对象、空间参照系统及空间参照系统之间的转换。\nWKB是什么？ WKB(well-know binary)是WKT的二进制表现形式，解决WKT表达冗余的问题，便于传输和存储在数据库中。\nGeoJSON是什么？ 以JSON的格式输出空间数据，便于被javascript等脚本调用。\nWKT与GeoJSON WKT与GeoJSON分为点、线、面、几何集合四种： 点 线 面 组合 Point MultiPoint LineString MultiLineString Polygon MultiPolygon GeometryCollection 类型 WKT GeoJSON Point POINT(10 10) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;Point\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;: [10, 10] } LineString LINESTRING(10 10, 20 30) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;Point\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;:[ [10, 10], [20, 30] ] } Polygon POLYGON(10 10, 15 16, 22 10, 30 32) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;Polygon\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;: [ [ [10, 10], [10, 10], [10, 10], [10, 10] ] ] } MultiPoint MULTIPOINT(*) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;MultiPoint\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;: [*] } MultiLineString MULTILINESTRING (*) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;MultiLineString\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;: [*] } MultiPolygon MULTIPOLYGON (*) { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;MultiPolygon\u0026rdquo;, \u0026ldquo;coordinates\u0026rdquo;: [*] } GEOMETRYCOLLECTION GEOMETRYCOLLECTION(POINT(2 3),LINESTRING(2 3,3 4)) - WKT与GeoJSON的区别 WKT是用来单独表示空间点、线、面数据，GeoJSON还可以用来表示空间数据和属性数据的集合 （crs、bbox属性）。 使用GeoPandas 读取 wkt字符串数据 获取山东省地图土地轮廓并使用GeoPandas加载展示\n通过百度地图api获取数据信息 将形状字符串转换为MultiPolygon类型数据 通过GeoPandas加载数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # encoding:utf-8 # 根据您选择的AK已为您生成调用代码 # 检测到您当前的AK设置了IP白名单校验 # 您的IP白名单中的IP非公网IP，请设置为公网IP，否则将请求失败 # 请在IP地址为0.0.0.0/0 外网IP的计算发起请求，否则将请求失败 import requests sds =None # 服务地址 host = \u0026#34;https://api.map.baidu.com\u0026#34; # 接口地址 uri = \u0026#34;/api_region_search/v1/\u0026#34; # 此处填写你在控制台-应用管理-创建应用后获取的AK ak = \u0026#34;\u0026#34; params = { \u0026#34;keyword\u0026#34;: \u0026#34;山东省\u0026#34;, \u0026#34;sub_admin\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;ak\u0026#34;: ak, \u0026#34;extensions_code\u0026#34;:1, \u0026#34;boundary\u0026#34;:1, } response = requests.get(url = host + uri, params = params) sds =None if response: # print(response.json()) sds = response.json() print(sds[\u0026#39;districts\u0026#39;]) # pd.DataFrame(sds[\u0026#39;districts\u0026#39;]) ","date":"2024-05-11T08:38:25Z","permalink":"http://localhost:1313/ai/%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E5%8F%AF%E8%A7%86%E5%8C%96/","title":"地理信息可视化"}]